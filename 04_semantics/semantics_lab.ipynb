{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acastellanos-ie/NLP-MBDS-EN/blob/main/04_semantics/semantics_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Session 4: Dense Semantics and Vector Spaces (Lab)\n",
        "\n",
        "**Learning Objective:**\n",
        "Understand how transforming text into high-dimensional numerical vectors (Embeddings) solves the fragility of classical rule-based NLP.\n",
        "\n",
        "We will revisit the exact failure from Session 2 (Synonyms and Passive Voice) and prove mathematically how geometry and Cosine Similarity solve the problem of meaning."
      ],
      "metadata": {
        "id": "WTgA6yWUHvHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Environment Setup\n",
        "# We use sentence-transformers to generate state-of-the-art dense embeddings.\n",
        "!pip install -q sentence-transformers numpy matplotlib seaborn"
      ],
      "metadata": {
        "id": "xuRPdnEkHvHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 1: The Geometry of Meaning\n",
        "We will load a small, highly efficient Embedding model. This model acts as a function: $f(text) \\rightarrow \\mathbb{R}^{384}$. It projects any text into a 384-dimensional space."
      ],
      "metadata": {
        "id": "8YpanpHbHvHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load a pre-trained model optimized for semantic similarity\n",
        "model_id = 'all-MiniLM-L6-v2'\n",
        "embedder = SentenceTransformer(model_id)\n",
        "\n",
        "print(f\"Model loaded. Vector dimensionality: {embedder.get_sentence_embedding_dimension()}\")"
      ],
      "metadata": {
        "id": "eLn_wY51HvHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 2: Solving the Parsing Failure\n",
        "In our previous, our rule-based system failed to connect `Who bought a car?` with `A brand new car was purchased by John` because the syntax and vocabulary were different.\n",
        "\n",
        "Let's map them into the vector space."
      ],
      "metadata": {
        "id": "3dbOJzeDHvHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The query\n",
        "query = \"Who bought a car?\"\n",
        "\n",
        "# The documents (Knowledge base)\n",
        "documents = [\n",
        "    \"A brand new car was purchased by John.\",  # Meaning matches query (Failed in Session 2)\n",
        "    \"Mary gave John a heavy book.\",            # Completely irrelevant\n",
        "    \"Alice traveled to Paris by train.\",       # Completely irrelevant\n",
        "    \"I want to buy a vehicle.\",                # Similar vocabulary, different intent\n",
        "]\n",
        "\n",
        "# Encode text into vectors\n",
        "query_vector = embedder.encode(query)\n",
        "document_vectors = embedder.encode(documents)\n",
        "\n",
        "print(f\"Query Vector Shape: {query_vector.shape}\")\n",
        "print(f\"Document Matrix Shape: {document_vectors.shape}\")"
      ],
      "metadata": {
        "id": "Oio5vdptHvHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 3: Mathematical Proof (Cosine Similarity)\n",
        "How do we know if two vectors mean the same thing? We measure the angle between them using **Cosine Similarity**.\n",
        "$Cosine(A, B) = \\frac{A \\cdot B}{||A|| ||B||}$"
      ],
      "metadata": {
        "id": "LZ-OjUXnHvHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "# Function to calculate cosine similarity from scratch\n",
        "def cosine_similarity(v1, v2):\n",
        "    return np.dot(v1, v2) / (norm(v1) * norm(v2))\n",
        "\n",
        "print(f\"Query: '{query}'\\n\")\n",
        "\n",
        "results = []\n",
        "for i, doc in enumerate(documents):\n",
        "    score = cosine_similarity(query_vector, document_vectors[i])\n",
        "    results.append((doc, score))\n",
        "    print(f\"Score: {score:.4f} | Document: '{doc}'\")"
      ],
      "metadata": {
        "id": "vs8MOUp8HvHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TAKEAWAY FOR THE STUDENT:\n",
        "Notice that `purchased` and `bought` are mapped to very similar coordinates.\n",
        "The model understands that `vehicle` and `car` are related, but intent matters.\n",
        "We didn't write a single syntax rule. Mathematics solved the semantic gap."
      ],
      "metadata": {
        "id": "7nVsrjjSPKJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 4: Building a Vector Database from Scratch\n",
        "Commercial Vector Databases (Pinecone, Milvus, Qdrant) are just highly optimized engines that perform the matrix multiplication we just did, but over billions of vectors.\n",
        "\n",
        "Let's do a bulk search using pure matrix multiplication (Dot Product), assuming the vectors are normalized."
      ],
      "metadata": {
        "id": "x3j-xPT4HvHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Normalize vectors (Length = 1) so Dot Product equals Cosine Similarity\n",
        "q_norm = query_vector / norm(query_vector)\n",
        "doc_norms = document_vectors / norm(document_vectors, axis=1, keepdims=True)\n",
        "\n",
        "# 2. The Core Engine of a Vector DB: Matrix Multiplication\n",
        "# Multiply the (1, 384) query vector by the (4, 384) document matrix transpose.\n",
        "similarity_scores = np.dot(q_norm, doc_norms.T)\n",
        "\n",
        "# 3. Retrieve the Top-K results (Sorting)\n",
        "top_k = 2\n",
        "best_indices = np.argsort(similarity_scores)[::-1][:top_k]\n",
        "\n",
        "print(\"--- Vector Database Search Results ---\")\n",
        "for idx in best_indices:\n",
        "    print(f\"Rank: Score={similarity_scores[idx]:.4f} -> {documents[idx]}\")\n",
        "\n",
        "# Visualizing the Vector Matrix Activity\n",
        "plt.figure(figsize=(12, 6))\n",
        "# We map the labels to the document strings using the best_indices\n",
        "labels = [documents[i] for i in best_indices]\n",
        "sns.heatmap(doc_norms[best_indices], cmap=\"coolwarm\", center=0, yticklabels=labels)\n",
        "plt.title(\"Dimensions of the Document Vector Space\")\n",
        "plt.xlabel(\"Latent Dimensions\")\n",
        "plt.ylabel(\"\") # Remove y-axis title\n",
        "plt.yticks(rotation=45) # Tilt the text\n",
        "plt.show()\n",
        "\n",
        "# This output becomes the 'Context' that we will feed into an LLM in Session 9 (RAG)."
      ],
      "metadata": {
        "id": "PWkqjawYHvHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd312aa5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the contribution to the dot product (q_i * d_i)\n",
        "# This shows in which dimensions the vectors align most\n",
        "contributions = q_norm * doc_norms[best_indices]\n",
        "\n",
        "# Select the top 20 dimensions with the highest average contribution for the top results\n",
        "mean_contributions = np.mean(contributions, axis=0)\n",
        "top_dims = np.argsort(np.abs(mean_contributions))[-20:]\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "labels = [documents[i] for i in best_indices]\n",
        "# We use xticklabels=top_dims to show the actual dimension indices\n",
        "sns.heatmap(contributions[:, top_dims], cmap=\"RdYlGn\", center=0, yticklabels=labels, xticklabels=top_dims)\n",
        "\n",
        "plt.title(\"Top 20 Dimensions Contributing Most to Similarity\")\n",
        "plt.xlabel(\"Vector Dimension Index\")\n",
        "plt.ylabel(\"\")\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "print(\"Green blocks represent dimensions where both the query and the document align strongly.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "087fe272"
      },
      "source": [
        "### What does this mean?\n",
        "\n",
        "These dimensions contain the 'features' that the model recognized in both the query and the best-matching documents (e.g., the concept of 'transaction' or 'automobiles').\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "anTqplpTRInv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}